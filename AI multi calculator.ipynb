{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from math import sin, cos, tan, radians\n",
    "import pyttsx3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"data.npz\", allow_pickle=True)\n",
    "features = data[\"features\"]\n",
    "labels = data[\"labels\"]\n",
    "word_dict = data[\"word_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_word_dict = dict([(k, v) for v , k in word_dict.items()])\n",
    "def get_sent(lst):\n",
    "    return \" \".join([rev_word_dict.get(i, \"\") for i in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pad_sequences(features, value=0, maxlen=8, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(160, 16))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dense(12, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - 2s 3ms/step - loss: 2.2893 - accuracy: 0.3002\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.6332 - accuracy: 0.6070\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.9613 - accuracy: 0.8270\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.5715 - accuracy: 0.9687\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.3222 - accuracy: 0.9947\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.1576 - accuracy: 0.9967\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0750 - accuracy: 0.9967\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0409 - accuracy: 0.9972\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0250 - accuracy: 0.9990\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 9.7215e-04 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 8.3743e-04 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 7.2281e-04 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.3117e-04 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.4967e-04 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 4.8083e-04 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 4.2201e-04 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.7002e-04 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.2548e-04 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.8669e-04 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.5405e-04 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.2422e-04 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.9846e-04 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.7611e-04 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.5612e-04 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.3869e-04 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.2338e-04 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.0990e-04 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 9.7815e-05 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 8.7315e-05 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 7.7950e-05 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.9441e-05 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.2027e-05 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.5522e-05 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 4.9617e-05 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 4.4408e-05 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.9740e-05 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.5562e-05 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.1905e-05 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.8536e-05 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.5641e-05 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.3013e-05 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.0575e-05 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.8532e-05 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.6614e-05 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.4897e-05 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.3364e-05 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.2020e-05 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.0817e-05 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 9.7036e-06 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 8.7130e-06 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 7.8433e-06 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 7.0491e-06 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.3531e-06 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.7177e-06 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.1455e-06 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 4.6285e-06 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 4.1632e-06 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.7512e-06 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.3747e-06 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.0365e-06 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.7368e-06 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.4648e-06 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.2221e-06 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.0029e-06 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.8033e-06 - accuracy: 1.0000\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 1s 3ms/step - loss: 1.6253e-06 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.4652e-06 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.3236e-06 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.1917e-06 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.0748e-06 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 9.7080e-07 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 8.7505e-07 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 7.8920e-07 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 7.1380e-07 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.4365e-07 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.8059e-07 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.2243e-07 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 4.7088e-07 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 4.2315e-07 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.8119e-07 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.4306e-07 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.0895e-07 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.7780e-07 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.4937e-07 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.2401e-07 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.0186e-07 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.8130e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25a700b16d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data, labels, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sent(sent):\n",
    "    l = sent.lower().replace(\".\", \"\").split()\n",
    "    n = [word_dict.get(i, 0) for i in l]\n",
    "    return n\n",
    "\n",
    "def predict(line):\n",
    "    line = line.lower()\n",
    "    encoded = encode_sent(line)\n",
    "    encoded = pad_sequences([encoded], value=0, maxlen=8, padding=\"post\")\n",
    "    pred = model.predict(encoded)\n",
    "    val = np.argmax(pred[0])\n",
    "\n",
    "    line = line.replace(\",\", \" \").split()\n",
    "    check = lambda x:  x.isdigit()\n",
    "    convt = lambda x: int(x)\n",
    "    num_lst = list(filter(check, line))\n",
    "    num_lst = list(map(convt, num_lst))\n",
    "\n",
    "    if val == 0:\n",
    "        sm = 0\n",
    "        for x in num_lst:\n",
    "            sm += int(x)\n",
    "        return f\"sum of {num_lst[0]} and {num_lst[1]} is {sm}\"\n",
    "\n",
    "    if val == 1:\n",
    "        if len(num_lst) != 2:\n",
    "            raise ValueError(f\"Required 2 numbers got {len(num_lst)}\")\n",
    "        sb = num_lst[0] - num_lst[1]\n",
    "        return f\"difference between {num_lst[0]} and {num_lst[1]} is {sb}\"\n",
    "\n",
    "    if val == 2:\n",
    "        if len(num_lst) != 2:\n",
    "            raise ValueError(f\"Required 2 numbers got {len(num_lst)}\")\n",
    "        ml = num_lst[0] * num_lst[1]\n",
    "        return f\"{num_lst[0]} multiplied by {num_lst[1]} is {ml}\"\n",
    "\n",
    "    if val == 3:\n",
    "        if len(num_lst) != 2:\n",
    "            raise ValueError(f\"Required 2 numbers got {len(num_lst)}\")\n",
    "        dv = num_lst[0] / num_lst[1]\n",
    "        return f\"{num_lst[0]} divided by {num_lst[1]} is {dv}\"\n",
    "\n",
    "    if val == 4:\n",
    "        if len(num_lst) != 1:\n",
    "            raise ValueError(f\"Required 1 number got {len(num_lst)}\")\n",
    "        sq = num_lst[0] ** 2\n",
    "        return f\"square of {num_lst[0]} is {sq}\"\n",
    "\n",
    "\n",
    "    if val == 5:\n",
    "        if len(num_lst) != 1:\n",
    "            raise ValueError(f\"Required 1 number got {len(num_lst)}\")\n",
    "        cb = num_lst[0] ** 3\n",
    "        return f\"cube of {num_lst[0]} is {cb}\"\n",
    "\n",
    "    if val == 6:\n",
    "        if len(num_lst) != 1:\n",
    "            raise ValueError(f\"Required 1 number got {len(num_lst)}\")\n",
    "        lg = log10(num_lst[0])\n",
    "        return f\"log of {num_lst[0]} is {lg}\"\n",
    "\n",
    "    if val == 7:\n",
    "        if len(num_lst) != 1:\n",
    "            raise ValueError(f\"Required 1 number got {len(num_lst)}\")\n",
    "        si = sin(radians(num_lst[0]))\n",
    "        return f\"sine value of {num_lst[0]} is {si}\"\n",
    "\n",
    "    if val == 8:\n",
    "        if len(num_lst) != 1:\n",
    "            raise ValueError(f\"Required 1 number got {len(num_lst)}\")\n",
    "        co = cos(radians(num_lst[0]))\n",
    "        return f\"cos value of {num_lst[0]} is {cs}\"\n",
    "\n",
    "    if val == 9:\n",
    "        if len(num_lst) != 1:\n",
    "            raise ValueError(f\"Required 1 number got {len(num_lst)}\")\n",
    "        tn = tan(radians(num_lst[0]))\n",
    "        return f\"tan of {num_lst[0]} is {tn}\"\n",
    "\n",
    "    if val == 10:\n",
    "        if len(num_lst) != 2:\n",
    "            raise ValueError(f\"Required 2 numbers got {len(num_lst)}\")\n",
    "        pw = num_lst[0] ** num_lst[1]\n",
    "        return f\"{num_lst[0]} raised to the power of {num_lst[1]} is {pw}\"\n",
    "\n",
    "    if val == 11:\n",
    "        if len(num_lst) != 1:\n",
    "            raise ValueError(f\"Required 1 number got {len(num_lst)}\")\n",
    "        fc = 1\n",
    "        for x in range(1, num_lst[0]+1):\n",
    "            fc *= x\n",
    "        return f\"Factorial of {num_lst[0]} is {fc}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "what is 7 + 8\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr \n",
    "r = sr.Recognizer() \n",
    "import pyttsx3\n",
    "engine = pyttsx3.init() \n",
    "\n",
    "with sr.Microphone() as source2: \n",
    "    r.adjust_for_ambient_noise(source2, duration=0.2) \n",
    "    audio2 = r.listen(source2) \n",
    "    text = r.recognize_google(audio2) \n",
    "    text = text.lower() \n",
    "    print(text)\n",
    "    ret = predict(text) \n",
    "    engine.say(ret) \n",
    "    engine.runAndWait() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a8e3956ebf9a0554e2d7a6d5d87eefcce415d526398f7b989230ab0943211e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
