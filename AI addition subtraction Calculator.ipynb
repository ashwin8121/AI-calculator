{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "AI addition, subtraction Calculator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashwin8121/AI-calculator/blob/main/AI%20addition%20subtraction%20Calculator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ps6q9xaXY_g"
      },
      "source": [
        "# A Program for AI Calculator Project\n",
        "    A Project By Ashwin Arumugam of class XII\n",
        "\n",
        "controls\n",
        "1. use shift+enter to run the cell\n",
        "2. run each cell\n",
        "3. or just hit ctrl+F9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilWjKRc1XY_h"
      },
      "source": [
        "Import the required Libraries\n",
        "  1. Tensorflow\n",
        "  2. numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klAwX2YhXY_i"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p2D4ByBXY_l"
      },
      "source": [
        "Definig the Features and labels and the dictionary containing the words and numbers realted to the words.\n",
        "These features and Labels are used to Train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5eGaBmlXY_l"
      },
      "source": [
        "features = [[3, 4, 5, 6, 7, 8, 9, 10], [11, 12, 5, 6, 7, 13, 9, 14], [15, 16, 9, 17], [18, 19, 20, 9, 21],\n",
        "            [22, 21, 9, 23], [22, 24, 9, 25], [6, 7, 20, 9, 16], [22, 21, 9, 20], [18, 7, 20, 9, 26], \n",
        "            [27, 7, 28, 9, 29], [4, 5, 18, 19, 20, 9, 30], [31, 7, 32, 9, 30], [33, 5, 27, 7, 34, 9, 35],\n",
        "            [11, 12, 5, 27, 7, 36, 9, 37], [18, 19, 38, 9, 39], [11, 12, 5, 18, 19, 40, 9, 41], \n",
        "            [42, 7, 43, 9, 44], [15, 16, 9, 45], [22, 46, 47, 48], [27, 7, 49, 9, 16], [15, 38, 9, 38], \n",
        "            [18, 7, 49, 9, 8], [18, 19, 50, 9, 51], [6, 7, 48, 9, 24], [52, 24, 53, 17], [6, 7, 54, 9, 55],\n",
        "            [15, 48, 9, 24], [42, 7, 56, 9, 25], [18, 7, 20, 9, 57], [11, 12, 56, 58, 16], [11, 12, 13, 59, 16],\n",
        "            [42, 7, 40, 9, 60], [4, 13, 58, 16], [61, 21, 59, 10], [18, 19, 40, 9, 62]]\n",
        "\n",
        "labels = [[0], [0], [0], [1], [1], [1], [0], [1], [1], [0], [1], [0], [0],\n",
        "          [0], [1], [1], [0], [0], [1], [0], [0], [1], [1], [0], [1], [0],\n",
        "          [0], [0], [1], [0], [1], [0], [0], [1], [1]]\n",
        "\n",
        "word_dict = {'hey': 3, 'calculate': 4, 'the': 5, 'sum': 6, 'of': 7, '9': 8, 'and': 9, '6': 10, 'what': 11, 'is': 12,\n",
        "             '5': 13, '13': 14, 'add': 15, '2': 16, '55': 17, 'difference': 18, 'between': 19, '10': 20, '3': 21,\n",
        "             'subtract': 22, '7': 23, '22': 24, '4': 25, '90': 26, 'addition': 27, '14': 28, '42': 29, '34': 30,\n",
        "             'sumation': 31, '15': 32, 'do': 33, '25': 34, '19': 35, '47': 36, '37': 37, '11': 38, '65': 39, \n",
        "             '100': 40, '45': 41, 'summation': 42, '198': 43, '31': 44, '32': 45, '28': 46, 'an': 47, '23': 48,\n",
        "             '12': 49, '76': 50, '30': 51, 'subract': 52, 'from': 53, '43': 54, '123': 55, '1': 56, '20': 57, \n",
        "             'plus': 58, 'minus': 59, '121': 60, 'calcuate': 61, '50': 62}\n",
        "\n",
        "labels = np.reshape(labels, (len(labels),))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT4rkhB0XY_o"
      },
      "source": [
        "rev_word_dict = dict([(v, k) for k, v in word_dict.items()])\n",
        "\n",
        "def decode_sentence(lst):\n",
        "    text = \" \".join([rev_word_dict.get(i, \"?\") for i in lst])\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nQtaeEBXY_q"
      },
      "source": [
        "Converting the raw list of number into a new list(training data) that can be understood by the Model and Machine.   \n",
        "This is done by a method called post padding. \n",
        "This method is also done to equalize all sentences upto maximum of 10 words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RViBrSAwXY_r"
      },
      "source": [
        "train_data = pad_sequences(features, maxlen=10, value=0, padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKsG6Y-1XY_t"
      },
      "source": [
        "Defining the model and Adding Layers to the model\n",
        "  1. The Embedding layer adds 100(first parameter in the Embedding layer) words as a vector representing the word to its graph      in the algorithm\n",
        "  2. The GlobalAveragePooling1D layer Redduces the dimension of the graph used in the algorithm\n",
        "  3. The Dense layer is the layer that containins Neurons. \n",
        "And then compile the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jECKOK6XY_u"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(100, 16))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(16, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqP0yMbdXY_w"
      },
      "source": [
        "Fitting or Training the model with the formated data/Training data and the labels for 150 times(number of epochs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5a0FBppXY_w",
        "outputId": "cd0da3f4-09fa-4006-f9e7-8ec489890a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_data, labels, epochs=150)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5143\n",
            "Epoch 2/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6918 - accuracy: 0.5714\n",
            "Epoch 3/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.6000\n",
            "Epoch 4/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.6000\n",
            "Epoch 5/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.6571\n",
            "Epoch 6/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.6571\n",
            "Epoch 7/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.6857\n",
            "Epoch 8/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.7143\n",
            "Epoch 9/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.7143\n",
            "Epoch 10/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.8857\n",
            "Epoch 11/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.9429\n",
            "Epoch 12/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.9143\n",
            "Epoch 13/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.9143\n",
            "Epoch 14/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.9143\n",
            "Epoch 15/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.9143\n",
            "Epoch 16/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.9429\n",
            "Epoch 17/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.9429\n",
            "Epoch 18/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.9429\n",
            "Epoch 19/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.9429\n",
            "Epoch 20/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.9429\n",
            "Epoch 21/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6690 - accuracy: 0.9429\n",
            "Epoch 22/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6673 - accuracy: 0.9429\n",
            "Epoch 23/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.9429\n",
            "Epoch 24/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.9429\n",
            "Epoch 25/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.9429\n",
            "Epoch 26/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.9429\n",
            "Epoch 27/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.9429\n",
            "Epoch 28/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.9429\n",
            "Epoch 29/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.9429\n",
            "Epoch 30/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.9429\n",
            "Epoch 31/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.9429\n",
            "Epoch 32/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.9429\n",
            "Epoch 33/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.9429\n",
            "Epoch 34/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.9429\n",
            "Epoch 35/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.9429\n",
            "Epoch 36/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.9429\n",
            "Epoch 37/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.9429\n",
            "Epoch 38/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.9429\n",
            "Epoch 39/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.9429\n",
            "Epoch 40/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.9429\n",
            "Epoch 41/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.9429\n",
            "Epoch 42/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6145 - accuracy: 0.9429\n",
            "Epoch 43/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.9429\n",
            "Epoch 44/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.9429\n",
            "Epoch 45/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.9429\n",
            "Epoch 46/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.9429\n",
            "Epoch 47/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.9429\n",
            "Epoch 48/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.9429\n",
            "Epoch 49/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.9429\n",
            "Epoch 50/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.9429\n",
            "Epoch 51/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.9429\n",
            "Epoch 52/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.9429\n",
            "Epoch 53/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.9429\n",
            "Epoch 54/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.9714\n",
            "Epoch 55/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.9714\n",
            "Epoch 56/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.9714\n",
            "Epoch 57/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.9714\n",
            "Epoch 58/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.9429\n",
            "Epoch 59/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5342 - accuracy: 0.9429\n",
            "Epoch 60/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5285 - accuracy: 0.9429\n",
            "Epoch 61/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.9429\n",
            "Epoch 62/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.9429\n",
            "Epoch 63/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.9429\n",
            "Epoch 64/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.9429\n",
            "Epoch 65/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.9429\n",
            "Epoch 66/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.9429\n",
            "Epoch 67/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.9429\n",
            "Epoch 68/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.9429\n",
            "Epoch 69/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.9429\n",
            "Epoch 70/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.9429\n",
            "Epoch 71/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.9429\n",
            "Epoch 72/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.9429\n",
            "Epoch 73/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.9714\n",
            "Epoch 74/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.9714\n",
            "Epoch 75/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.9714\n",
            "Epoch 76/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.9714\n",
            "Epoch 77/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.9714\n",
            "Epoch 78/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.9714\n",
            "Epoch 79/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.9714\n",
            "Epoch 80/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.9714\n",
            "Epoch 81/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.9714\n",
            "Epoch 82/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.9714\n",
            "Epoch 83/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3840 - accuracy: 0.9714\n",
            "Epoch 84/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.9714\n",
            "Epoch 85/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.9714\n",
            "Epoch 86/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.9714\n",
            "Epoch 87/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.9714\n",
            "Epoch 88/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.9714\n",
            "Epoch 89/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.9714\n",
            "Epoch 90/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.9714\n",
            "Epoch 91/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3340 - accuracy: 0.9714\n",
            "Epoch 92/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.9714\n",
            "Epoch 93/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.9714\n",
            "Epoch 94/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.9714\n",
            "Epoch 95/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.9714\n",
            "Epoch 96/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.9714\n",
            "Epoch 97/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.9714\n",
            "Epoch 98/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.9714\n",
            "Epoch 99/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.9714\n",
            "Epoch 100/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2796 - accuracy: 0.9714\n",
            "Epoch 101/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.9714\n",
            "Epoch 102/150\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2688 - accuracy: 0.9714\n",
            "Epoch 103/150\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2633 - accuracy: 0.9714\n",
            "Epoch 104/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2580 - accuracy: 0.9714\n",
            "Epoch 105/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2534 - accuracy: 0.9714\n",
            "Epoch 106/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2486 - accuracy: 0.9714\n",
            "Epoch 107/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.9714\n",
            "Epoch 108/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.9714\n",
            "Epoch 109/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2348 - accuracy: 0.9714\n",
            "Epoch 110/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.9714\n",
            "Epoch 111/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2260 - accuracy: 0.9714\n",
            "Epoch 112/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9714\n",
            "Epoch 113/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2168 - accuracy: 0.9714\n",
            "Epoch 114/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9714\n",
            "Epoch 115/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9714\n",
            "Epoch 116/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2028 - accuracy: 0.9714\n",
            "Epoch 117/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1988 - accuracy: 0.9714\n",
            "Epoch 118/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1950 - accuracy: 0.9714\n",
            "Epoch 119/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1911 - accuracy: 0.9714\n",
            "Epoch 120/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1875 - accuracy: 0.9714\n",
            "Epoch 121/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1837 - accuracy: 0.9714\n",
            "Epoch 122/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9714\n",
            "Epoch 123/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.9714\n",
            "Epoch 124/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1738 - accuracy: 1.0000\n",
            "Epoch 125/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 1.0000\n",
            "Epoch 126/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 1.0000\n",
            "Epoch 127/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1640 - accuracy: 1.0000\n",
            "Epoch 128/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1606 - accuracy: 1.0000\n",
            "Epoch 129/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1572 - accuracy: 1.0000\n",
            "Epoch 130/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1538 - accuracy: 1.0000\n",
            "Epoch 131/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 1.0000\n",
            "Epoch 132/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 1.0000\n",
            "Epoch 133/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 1.0000\n",
            "Epoch 134/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 1.0000\n",
            "Epoch 135/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1372 - accuracy: 1.0000\n",
            "Epoch 136/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 1.0000\n",
            "Epoch 137/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1315 - accuracy: 1.0000\n",
            "Epoch 138/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1290 - accuracy: 1.0000\n",
            "Epoch 139/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 1.0000\n",
            "Epoch 140/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 1.0000\n",
            "Epoch 141/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 1.0000\n",
            "Epoch 142/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 1.0000\n",
            "Epoch 143/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 1.0000\n",
            "Epoch 144/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1152 - accuracy: 1.0000\n",
            "Epoch 145/150\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1131 - accuracy: 1.0000\n",
            "Epoch 146/150\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.1110 - accuracy: 1.0000\n",
            "Epoch 147/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1090 - accuracy: 1.0000\n",
            "Epoch 148/150\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1070 - accuracy: 1.0000\n",
            "Epoch 149/150\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1051 - accuracy: 1.0000\n",
            "Epoch 150/150\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1033 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2ae1218710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD7ZZVN4XY_0"
      },
      "source": [
        "Saving the model. saving the model can save a lot of time and memory. load the model using the function tensorflow.keras.model.load_model(<model name>).\n",
        "loadin the model does not require treaining the model each and every time the user runs the program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--Jn7CvZXY_1"
      },
      "source": [
        "model.save(\"addition_subraction_classifier.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVee5Pj9XY_3"
      },
      "source": [
        "Prectiction Time!!!. Run the cell. Enter a sentence related to addition or subraction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "wAWxdIrQXY_3",
        "outputId": "483e7120-8682-4e1b-b006-5cb82be7bbf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "def review_encode(s):\n",
        "    encoded = []\n",
        "\n",
        "    for word in s:\n",
        "        if word.lower() in word_dict:\n",
        "            encoded.append(word_dict[word.lower()])\n",
        "    return encoded\n",
        "\n",
        "print(\"Example: what is he sum of 4 and 3, add 3 and 5, etc.\")\n",
        "line = input(\"Enter the sentence related to addition or subraction\").lower()\n",
        "nline = line.strip().split(\" \")\n",
        "encode = review_encode(nline)\n",
        "encode = pad_sequences([encode], value=0, padding=\"post\", maxlen=10) # make the data 250 words long\n",
        "predict = model.predict(encode)\n",
        "pred = predict[0]\n",
        "if round(pred[0]) == 0:\n",
        "    print(\"Addition\")\n",
        "else:\n",
        "    print(\"Subraction\")\n",
        "\n",
        "line_lst = line.split()\n",
        "val_lst = []\n",
        "for x in line_lst:\n",
        "    if x.isdigit():\n",
        "        val_lst.append(int(x))\n",
        "\n",
        "val1, val2 = val_lst\n",
        "ans = None\n",
        "if round(pred[0]) == 0:\n",
        "    ans = val1 + val2\n",
        "    prediction = 100 - pred[0]*100\n",
        "else:\n",
        "    ans = val1 - val2\n",
        "    prediction = 100*pred[0]\n",
        "print(\"Prediction is :\", round(prediction, 2))\n",
        "print(ans)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example: what is he sum of 4 and 3, add 3 and 5, etc.\n",
            "difference between 100 and 30\n",
            "Subraction\n",
            "Prediction is : 94.55\n",
            "70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el32Os51kayz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}